import networkx as nx
import numpy as np
from scipy.optimize import linprog
from collections import defaultdict
import random

# Step 1: Build HL₂(G) from a base graph G and dummy ordering
def build_HL2_explicit(G, phi):
    edge_vertices = []
    for u, v in G.edges():
        if phi[u] < phi[v]:
            edge_vertices.append((u, v))
        else:
            edge_vertices.append((v, u))
    HL2 = nx.Graph()
    HL2.add_nodes_from(edge_vertices)
    for idx1, (u1, v1) in enumerate(edge_vertices):
        for idx2 in range(idx1 + 1, len(edge_vertices)):  # Avoid duplicates/self-loops
            u2, v2 = edge_vertices[idx2]
            if (u1 == u2 and v1 != v2) or (v1 == v2 and u1 != u2):
                HL2.add_edge((u1, v1), (u2, v2))
    return HL2

# Step 2: Generate Label-Cover with ε noise and planted labeling
def generate_label_cover_fixed(G, k, epsilon, seed_val=42):
    rng = np.random.default_rng(seed_val)
    nodes = list(G.nodes())
    labeling = {v: rng.integers(0, k) for v in nodes}
    constraints = {}
    for u, v in G.edges():
        if rng.random() < epsilon:
            pi = list(rng.permutation(np.arange(k)))
        else:
            shift = (labeling[v] - labeling[u]) % k
            pi = [(i + shift) % k for i in range(k)]
        constraints[(u, v)] = pi
        # Inverse for (v,u)
        inverse_pi = [0] * k
        for i in range(k):
            inverse_pi[pi[i]] = i
        constraints[(v, u)] = inverse_pi
    return labeling, constraints

# Step 3: Evaluate value of labeling (safe version)
def evaluate_val_G(G, labeling, constraints):
    satisfied = 0
    for (u, v) in G.edges():
        if u in labeling and v in labeling:
            pi = constraints[(u, v)]
            if pi[labeling[u]] == labeling[v]:
                satisfied += 1
    return satisfied / G.number_of_edges()

# Step 4: LP relaxation with consistency and satisfaction constraints
def approximate_lp_phi(HL2, constraints, k, G):
    node_list = list(HL2.nodes())
    n = len(node_list)
    num_vars = n * k
    c = np.zeros(num_vars)  # feasibility problem (no optimization)
    
    A_eq = []
    b_eq = []

    # Sum-to-1 for each HL2 node
    for i in range(n):
        constraint = np.zeros(num_vars)
        for l in range(k):
            constraint[i * k + l] = 1
        A_eq.append(constraint)
        b_eq.append(1)

    # Build head and tail groups
    head_groups = defaultdict(list)
    tail_groups = defaultdict(list)
    for idx, (u, v) in enumerate(node_list):
        head_groups[v].append(idx)
        tail_groups[u].append(idx)

    # Consistency across all HL2 nodes sharing the same head
    for v, group in head_groups.items():
        rep = group[0]
        for other in group[1:]:
            for l in range(k):
                constraint = np.zeros(num_vars)
                constraint[rep * k + l] = 1
                constraint[other * k + l] = -1
                A_eq.append(constraint)
                b_eq.append(0)

    # Consistency across all HL2 nodes sharing the same tail
    for u, group in tail_groups.items():
        rep = group[0]
        for other in group[1:]:
            for l in range(k):
                constraint = np.zeros(num_vars)
                constraint[rep * k + l] = 1
                constraint[other * k + l] = -1
                A_eq.append(constraint)
                b_eq.append(0)

    bounds = [(0, 1) for _ in range(num_vars)]

    result = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')

    Phi = {}
    lp_value = 0.0

    if result.success:
        x_vec = result.x
        for i in range(n):
            label_vals = x_vec[i * k:(i + 1) * k]
            best_label = int(np.argmax(label_vals))
            Phi[node_list[i]] = best_label

        # Compute LP objective: fractional satisfaction of projection constraints
        satisfied = 0
        total = 0
        for u, v in G.edges():
            if (u, v) in constraints:
                pi = constraints[(u, v)]
                u_idx = next((i for i, (a, _) in enumerate(node_list) if a == u), None)
                v_idx = next((i for i, (_, b) in enumerate(node_list) if b == v), None)
                if u_idx is not None and v_idx is not None:
                    for l in range(k):
                        m = pi[l]
                        satisfied += x_vec[u_idx * k + l] * x_vec[v_idx * k + m]
                    total += 1
        if total > 0:
            lp_value = satisfied / total
    else:
        for i in range(n):
            Phi[node_list[i]] = random.randint(0, k - 1)
        lp_value = 0.0

    return Phi, lp_value

# Step 5: Majority decode with fallback
def majority_decode(HL2, phi, G, k):
    votes = {v: [] for v in G.nodes()}
    for (u, v), label in phi.items():
        votes[v].append(label)
    decoded = {}
    for v in G.nodes():
        if votes[v]:
            decoded[v] = max(set(votes[v]), key=votes[v].count)
        else:
            decoded[v] = np.random.randint(k)
    return decoded

