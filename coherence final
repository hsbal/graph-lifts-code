import networkx as nx
import numpy as np
import pandas as pd
from scipy.sparse.linalg import expm_multiply
from collections import deque
import random

# === HL′₂ symmetric lift ===
def build_HL2(G):
    top = {f"{v}_top" for v in G.nodes()}
    bottom = {f"{v}_bot" for v in G.nodes()}
    B = nx.Graph()
    B.add_nodes_from(top, bipartite=0)
    B.add_nodes_from(bottom, bipartite=1)
    for u, v in G.edges():
        B.add_edge(f"{u}_top", f"{v}_bot")
        B.add_edge(f"{v}_top", f"{u}_bot")
    return nx.line_graph(B)

# === Quantum coherence metrics ===
def ipr(psi):
    return np.sum(np.abs(psi)**4)

def purity(rho):
    return np.trace(rho @ rho).real

def rel_entropy_coherence(rho):
    evals_rho = np.clip(np.linalg.eigvalsh(rho), 0, None)  # Safe eigenvalues
    evals_diag = np.clip(np.diag(rho).real, 0, None)       # Diagonal entries (probabilities)
    S_rho = -np.sum(evals_rho * np.log2(evals_rho + 1e-12))
    S_diag = -np.sum(evals_diag * np.log2(evals_diag + 1e-12))
    return S_diag - S_rho

def coherence_metrics(A, k=5):
    vals, vecs = np.linalg.eigh(A)
    top_vecs = vecs[:, -k:]  # Top-k eigenvectors
    n = A.shape[0]
    rho = np.zeros((n, n), dtype=complex)
    iprs = []
    for v in top_vecs.T:
        rho += np.outer(v, v.conj())
        iprs.append(ipr(v))
    rho /= k
    return np.mean(iprs), purity(rho), rel_entropy_coherence(rho)

# === Return probability simulation ===
def bfs_subgraph(G, start_node, max_nodes=2000):
    visited, queue = set(), deque([start_node])
    while queue and len(visited) < max_nodes:
        node = queue.popleft()
        if node not in visited:
            visited.add(node)
            neighbors = list(G.neighbors(node))
            random.shuffle(neighbors)
            queue.extend(n for n in neighbors if n not in visited)
    return G.subgraph(visited).copy()

def simulate_return(G, node, T=10, steps=50):  # Lightweight simulation
    node_list = list(G.nodes())
    index_map = {v: i for i, v in enumerate(node_list)}
    idx = index_map[node]
    A = nx.to_scipy_sparse_array(G, nodelist=node_list, format='csr', dtype=complex)
    psi0 = np.zeros(len(G), dtype=complex)
    psi0[idx] = 1.0
    times = np.linspace(0, T, steps)
    returns = np.array([abs(expm_multiply(-1j * A * t, psi0)[idx])**2 for t in times])
    return np.mean(returns), np.max(returns), np.std(returns)

# === Experiment loop ===
def run_lift_experiment(base_graph, name, max_level=3):
    G = base_graph.copy()
    results = []
    for level in range(0, max_level + 1):
        A = nx.to_numpy_array(G)
        avg_ipr, avg_purity, rel_ent = coherence_metrics(A)
        sub = bfs_subgraph(G, list(G.nodes())[0], max_nodes=1500)
        mean_ret, peak_ret, std_ret = simulate_return(sub, list(sub.nodes())[0])
        results.append({
            "graph": name,
            "lift_level": level,
            "nodes": G.number_of_nodes(),
            "avg_ipr": avg_ipr,
            "avg_purity": avg_purity,
            "avg_rel_entropy": rel_ent,
            "mean_return": mean_ret,
            "peak_return": peak_ret,
            "std_return": std_ret
        })
        if level < max_level:
            G = build_HL2(G)
    return pd.DataFrame(results)

# === Main: Run for K4 and 3-regular ===
if __name__ == "__main__":
    # Create graphs
    k4 = nx.complete_graph(4)
    r3 = nx.random_regular_graph(3, 20, seed=42)

    # Run experiments
    df_k4 = run_lift_experiment(k4, "K4")
    df_r3 = run_lift_experiment(r3, "3-regular (n=20)")

    # Save as CSV
    df_k4.to_csv("k4_coherence.csv", index=False)
    df_r3.to_csv("r3_coherence.csv", index=False)

    # Print summaries
    print("=== K4 Coherence Metrics ===")
    print(df_k4)
    print("\n=== 3-Regular Coherence Metrics ===")
    print(df_r3)

    # Export LaTeX tables
    def to_latex(df, caption):
        return df.to_latex(index=False, float_format="%.4f",
                           caption=caption,
                           label="tab:" + caption.lower().replace(" ", "_").replace("(", "").replace(")", "").replace("-", ""))

    with open("k4_table.tex", "w") as f:
        f.write(to_latex(df_k4, "Coherence Metrics for K4 (Corrected)"))

    with open("r3_table.tex", "w") as f:
        f.write(to_latex(df_r3, "Coherence Metrics for 3-Regular Graph (Corrected)"))

    print("\nLaTeX tables saved as k4_table.tex and r3_table.tex.")
